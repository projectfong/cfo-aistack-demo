# ğŸ§± cfo-aistack: A Modular, Composable AI Stack

> A fully offline, local-first, pluggable AI runtime built from purpose-driven layers.  
> Each module can run standalone â€” or compose together via Docker Compose.

---

## âœ… Core Modules

| Module         | Role / Responsibility                                     | Status |
| -------------- | --------------------------------------------------------- | ------ |
| `cfo-vessel`   | Model launcher, memory manager, GPU loader (LLM engine)   | âœ… Done |
| `cfo-embed`    | Embedding encoder, vectorizer (e.g. `e5`)   | âœ… Done |
| `cfo-router`   | Smart router: model selection, RAG orchestration, prompt engineering | âœ… Done |
| `cfo-fast-rag` | Lightweight retrieval API for Qdrant collections          | âœ… Done |

---

## ğŸ“¦ Combine via `docker-compose.yml`

### Folder structure (recommended)

```

cfo-aistack/
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env
â””â”€â”€ setup.sh â† clone all repos below
â”œâ”€â”€ cfo-vessel/     â† LLM runtime
â”œâ”€â”€ cfo-embed/      â† Embedding encoder API
â”œâ”€â”€ cfo-router/     â† Smart router
â”œâ”€â”€ cfo-fast-rag/   â† Vector search API to Qdrant
â””â”€â”€ shared/         â† Shared logs, models, configs (mounted in each)

````

### Example `docker-compose.yml`

```yaml
services:
  vessel:
    build: ./cfo-vessel
    container_name: cfo-vessel
    volumes:
      - ./shared/models:/vessel/models
      - ./shared/logs:/vessel/logs
    ports:
      - "8000:8000"
    environment:
      - NVIDIA_VISIBLE_DEVICES=all

  embed:
    build: ./cfo-embed
    container_name: cfo-embed
    volumes:
      - ./shared/logs:/embed/logs
    ports:
      - "8005:8005"

  router:
    build: ./cfo-router
    container_name: cfo-router
    depends_on:
      - vessel
    ports:
      - "8001:8001"

  rag:
    build: ./cfo-fast-rag
    container_name: cfo-fast-rag
    depends_on:
      - embed
    ports:
      - "8002:8002"

networks:
  default:
    name: cfo-net
````

---

## ğŸ”§ Build Strategy

1. âœ… **Build standalone**

   * Each module should work on its own
   * Confirm working APIs, log output, Docker build

2. ğŸ”— **Connect by dependency**

   * Use `depends_on` and shared volumes
   * Connect via internal Docker hostnames (`http://embed:8005`, etc)

3. ğŸ“¦ **Wrap in single repo**

   * Top-level folder contains all modules
   * Compose handles lifecycle, logs, network

4. ğŸ§ª **Add health check scripts**

   * Validate LLMs, embeddings, vector insertions, chaining
   * CLI test tools for prompt/embedding/model/invoke

---

## ğŸ” Security + Control

Once deployed, you fully control:

* ğŸ§  Model lifecycle, usage, memory
* ğŸ” Access control (headers, IP filters, token auth)
* ğŸ“¦ Embedding model choice (instructional, multilingual, domain)
* ğŸ§¾ Prompt logging, usage auditing
* ğŸ“š RAG logic and indexing flow
* âš™ï¸ On-disk model integrity (hash checks, idle unload)

---

## ğŸ Summary

Once complete, `cfo-aistack` becomes a **modular, auditable, offline AI platform**.
Models live and die on your terms. Prompts are visible. No cloud inference, no data leak.

Workflow:

```
Prompt â†’ Router â†’ Fast-RAG/Vessel or both â†’ Output
```

Everything runs on your metal. Fully portable. Fully yours.

---

## ğŸ”¹ Disclaimer

This repository is a **blueprint/demo**.
Modules are described with examples; full implementations are maintained privately.

## ğŸ”¹ License

All Rights Reserved. See [LICENSE.md](./LICENSE.md).

